{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [UC16] Evaluate dataset preprocessing influence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Load datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "DATASET = pd.read_csv('../data/NATICUSdroid.csv')\n",
    "X = DATASET.iloc[:, :-1]\n",
    "y, _ = pd.factorize(DATASET.iloc[:, -1])\n",
    "\n",
    "DATASET_VARIANTS = []"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Provide dataset preprocessed variants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler, PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "scaler_standard = StandardScaler()\n",
    "DATASET_scaled_standard = pd.DataFrame(scaler_standard.fit_transform(X), columns=X.columns)\n",
    "DATASET_VARIANTS.append({\"name\": \"standard_scaled\", \"data\": DATASET_scaled_standard.to_numpy()})\n",
    "\n",
    "scaler_min_max = MinMaxScaler()\n",
    "DATASET_scaled_min_max = pd.DataFrame(scaler_min_max.fit_transform(X), columns=X.columns)\n",
    "DATASET_VARIANTS.append({\"name\": \"min_max_scaled\", \"data\": DATASET_scaled_min_max.to_numpy()})\n",
    "\n",
    "scaler_robust = RobustScaler()\n",
    "DATASET_scaled_robust = pd.DataFrame(scaler_robust.fit_transform(X), columns=X.columns)\n",
    "DATASET_VARIANTS.append({\"name\": \"robust_scaled\", \"data\": DATASET_scaled_robust.to_numpy()})\n",
    "\n",
    "pca = PCA(n_components=0.95)\n",
    "DATASET_pca = pd.DataFrame(pca.fit_transform(X))\n",
    "DATASET_VARIANTS.append({\"name\": \"pca\", \"data\": DATASET_pca.to_numpy()})\n",
    "\n",
    "poly = PolynomialFeatures(degree=2, interaction_only=True, include_bias=False)\n",
    "DATASET_poly = pd.DataFrame(poly.fit_transform(X), columns=poly.get_feature_names_out(X.columns))\n",
    "DATASET_VARIANTS.append({\"name\": \"poly\", \"data\": DATASET_poly.to_numpy()})\n",
    "\n",
    "selector = VarianceThreshold(threshold=0.01)\n",
    "DATASET_feature_selected = pd.DataFrame(selector.fit_transform(X), columns=X.columns[selector.get_support()])\n",
    "DATASET_VARIANTS.append({\"name\": \"feature_selected\", \"data\": DATASET_feature_selected.to_numpy()})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Define exmperimet parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "EXPERIMENT_NAME = 'UC16_evaluate_dataset_preprocessing_influence'\n",
    "HYPERPARAMETERS = {\n",
    "            'n_layers': 5,\n",
    "            'filters': 32,\n",
    "            'kernel_size': 3,\n",
    "            'activation': 'sigmoid',\n",
    "            'use_batch_normalization': True,\n",
    "            'dropout_rate': 0.2,\n",
    "            'optimizer': 'Adam',\n",
    "            'learning_rate': 1e-4,\n",
    "            'batch_size': 32,\n",
    "        }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Run testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mlcb.models.tabular.pytorch import PytorchDenseNetTunable\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "for dataset in DATASET_VARIANTS:\n",
    "    X = dataset['data'][:, :-1]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, shuffle=True)\n",
    "    cls = PytorchDenseNetTunable(X_train, y_train, X_test, y_test)\n",
    "    cls.train(experiment_name=EXPERIMENT_NAME, hyperparameters=HYPERPARAMETERS, run_name=dataset['name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Analyze training process\n",
    "\n",
    "Tuning statistics are available on address: http://127.0.0.1:5000/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Close MLFlow for this experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cls.logger._close_mlflow()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
